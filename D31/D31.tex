\documentclass[a4paper,11pt,pdf]{pacmanreport}

\usepackage{helvet}
\usepackage{graphicx}
\graphicspath{{images/}{../shared_images/}}
\usepackage{bm}
\usepackage{mhchem} % Package for chemical equation typesetting
\usepackage{siunitx} % Provides the \SI{}{} command for typesetting SI units
\usepackage{epstopdf}
\usepackage{booktabs}
\usepackage{floatrow}

\usepackage{amsmath} 
\usepackage{amssymb}  
\usepackage{colortbl} 
\usepackage{gensymb}
\usepackage{algorithm}
\usepackage{algorithmic}

% Table float box with bottom caption, box width adjusted to content
\newfloatcommand{capbtabbox}{table}[][\FBwidth]

% The following is used to make packages hyperref and cite work together
\makeatletter
\let\NAT@parse\undefined
\makeatother

\DeclareMathOperator{\rad}{rad}

\usepackage[bookmarks=true,hyperfootnotes=true]{hyperref}
\hypersetup{
			colorlinks=true,
			linkcolor=blue,
			anchorcolor=blue,
			citecolor=blue,
			urlcolor=blue,
            filecolor=blue,
			pdftitle={Deliverable 3.1}
}

%% ================================
%% PROJECT INFO

\project{}
\projectid{FP7-IST-60918}
\projectstart{1 March 2013}
\duration{36}

%% ================================
%% DELIVERABLE INFO

\title{Control algorithms for haptic object exploration}
\deliverableid{DR 3.1}
\author{C. Rosales, M. Bonilla, G. Santaera, E. Luberto, M. Gabiccini}
\address{Centro di Ricerca ``E. Piaggio'', Universit\`{a} di Pisa}
\email{carlos.rosales@for.unipi.it}
\headertitle{Haptic exploration}
\headerauthor{C. Rosales, G. Santaera, E. Luberto, M. Gabiccini}

\duedate{2015-02-28}
\submissiondate{2014-02-28}
\leadpartner{Universit\`{a} di Pisa}
\revision{draft}
\disseminationlevel{PU}


%% UNCOMMENT: to get the logo; if you've copied this file to a directory yearX/wpY/ then this should work
\reportlogo{pacmanlogo.png}


\begin{document}

\maketitle

\begin{abstract}
\noindent This report describes activities related to the development of haptic object exploration methodologies. Object shape refinement and friction coefficient estimation require low-level controllers that allow contour tracing interaction as well as a sophisticated sensorization of the exploratory probe. This report presents the efforts on providing controllers to perform sliding and rolling of a fingertip over a surface, integrating controller strategy with vision, implementing a robust testbed to simulate results, and last but not least, specifying the designs on the sensorization of the Pisa/IIT SoftHand.
\end{abstract}

\vspace{.2em}
\hrule

\footnotesize

\tableofcontents

\normalsize

\newpage

\section*{Executive Summary}
\includegraphics[height=80pt]{pacmanlogo.png}\\
This report describes the activities within the PaCMan consortium to define methodologies for \emph{haptic object exploration}. The material included in this report shows the results of Task 3.1 (M 1-24). Aside, progress of Task 3.2 (M 1-36) is presented as well as the envision of a promising approach to tackle the problem within, particularly the information gathering for unknown objects or in cases where partial information is available.

\section*{Role of haptic object exploration in PaCMan}

This deliverable reports the research done on finding a methodology to explore objects and gather their haptic properties such as the static and dynamic friction coefficient. 
%To this end, \emph{control algorithms} and \emph{innovative sensors} are developed.

\section*{Contribution to the PaCMan scenario}

The multi-modal object representation to be reported in WP2 requires information about the shape and haptic properties of an object.
The active acquisition of such information is essential to build the representation of a particular object. The exploratory strategies which combine low-level control algorithms developed by the UNIPI team, high-level decision making strategies to be completed by UoB team, together with a sensorized adaptive hand as proposed from the UNIPI team, make this possible.

Additionally, the developed algorithms make no assumption on how the gathered information is encoded. This provides a versatile testbed to contrast the representation coming from WP2 with other approaches.

\newpage

\section{Tasks, objectives, results}

\subsection{Planned work}

This report must show the results of Task 3.1. Particularly, it should describe reactive control strategies for haptic exploration of an object by a robotic hand, consisting of contour tracing of the object surface and finger rolling over the object surface, as well as strategies for extracting higher-order geometric features and frictional properties.

In Task 3.3 we planned to implement the active gaze model we presented in year 1 in the robot platform. This was intended to be used in the demonstration 5.2. The hypothesis to be tested is whether a reward based framework for active gaze control for grasping under positional uncertainty can be extended to work on real objects. The initial assumption was that the active gaze control model would work with a prior model of the object shape. The overall goal was to show that active gaze can improve the reliability of grasping and manipulation.

\subsection{Actual work performed}

We can proudly say that Task 3.1 has been accomplished, and Sec.~\ref{sec:ControlAlgorithms} summarizes the results following the planned activities accurately.

%Sec.~\ref{sec:Simulation} describes the simulation environment that will be used to test the results of Tasks~3.1 and~3.2. The reason behind implementing another simulation environment different from the one presented in Sec.~\ref{sec:ControlAlgorithms} is the integration with vision and to the expected results from Task~3.2, which was acknowledge after obtaining the results of Task~3.1.

The fact that the object shape uncertainty is reduced by making contact with the object, combined with the adaptability of the Pisa/IIT SoftHand to any kind of surface, shaped the idea of using the hand as sophisticated exploratory probe. Sec.~\ref{sec:IMUGlove} ans~\ref{sec:SenseOfTouch} provide glove-inspired solutions to read the hand configuration as well as the contact information to estimate accurately the object shape as the result of grasping the object. The solution can help greatly in situations where only partial visual information is available, as challenged in Task 3.2, thus we believe that this research line deserves further attention as seems beneficial to accomplish the project goals.

Work on grasping of novel objects in work package 4 progressed much faster than we expected. Thus this was taken as the grasping method to be combined with active gaze. The active gaze approach taken has been informed by the fact that experiments in our IJRR submission for WP4 have shown us that grasp failure is typically driven by the incompleteness of the point cloud near to suggested grasp points and along the final grasp trajectory. In addition tests with differing numbers of views of the test object prior to grasping showed that the more views one has from an object, the greater the probability of grasping success for this object. In addition we have used a wrist mounted depth camera for the active gaze method.

We are extending the reward based method from \cite{nunez2013models} to the case of incomplete point clouds. We require a measure of the proportion of the total possible coverage given by the incomplete object model. To this end we are currently investigating the use of an octree representation, called octmap \cite{hornung13auro}, for online object modelling and sensor data fusion. The octmap of a given object allows the representation of occupied (known voxels belonging to a segmented object), free (voxels that do not belong to an object), and unknown areas of the scene, which might belong to the object if they are near known and occupied voxels. We are now implementing a method for estimation of the safety of a grasp trajectory given this octmap. We are also testing different measures of the coverage of the object pertinent to a candidate grasp given the point cloud and the octmap representations.

Previously, in year one, we presented an algorithm for active gaze in the case where the object model is known, and the pose is uncertain. This was tested in simulation, and shown to fit human data. Relevant work on grasping under incomplete information is that by Bohg and Kragic \cite{bohg:icra11}. There the approach is not active gaze to fill in information, but to use a symmetry prior to complete missing object parts. An active vision system for grasping is described in \cite{gratal:irosws10}, but in this the main task of gaze control is to find and fixate on the object to support a visual servoing routine. A recent workshop at RSS 2014 on active information gathering for grasping was notable in that none of the papers considered active vision, but instead focussed on the type of approaches we study Task 4.4. Thus the area is underexplored.

% \subsection{Relation to the state-of-the-art}
% How are the obtained results related to the state-of-the-art?
% This part is usually discussed in the corresponding subsection. Therefore, % a global 'Relation to the state-of-the-art' is unnecessary

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Work directly into the following .tex files

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Carlos
% Learning the haptic characteristics of objects by exploration in-hand
\input{./inputFiles/LearningHapticCharacteristicsObjectsExplorationInHand.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Carlos
% SimulationEnvironment moving the gazebo part to here, since testing in simulation is advised by the Tasks.
% \input{./inputFiles/SimulationEnvironment.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Gaspare and Emanuele
% Endowing the Pisa/IIT SoftHand with the sense of touch
\input{./inputFiles/SoftHandWithSenseOfTouch.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Marco Gabiccini
% Low-cost, Fast and Accurate Reconstruction of Robotic and Human Postures 
% via IMU Measurements
\input{./inputFiles/ReconstructionPosturesImuMeasurements.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Jeremy Wyatt
% Active Gaze
% \input{./inputFiles/ActiveGaze.tex}

\section{Annexes}

Which papers / articles are included in the report? Mention titles, authors, publication info; abstract; and a one-liner relating the publication back to the discussion on actual work performed.


\bibliographystyle{IEEEtran}
\bibliography{../shared_bibliography/abbreviations,./bibliography/D31}



\end{document}
