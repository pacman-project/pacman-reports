%%% Object Grasping Dataset 

\subsubsection{Object Grasping Dataset}
\label{sec:ObjectGraspingDataset}

In this section we present an object grasping dataset, collected at the University of Pisa, to be used within the PaCMan project as a tool to perform high level planning and grasping.
The dataset contains a series of grasps performed on kitchen environment objects by a human operator with the aid of the Pisa/IIT SoftHand. The operator wears
a motorized handle on his right arm, which supports and operates the SoftHand, while it performs grasps on objects. 
The dataset is populated with 8-10 seconds long records for each object so that in each record the user has constant access to relative and/or absolute hand posture, object pose, hand joints positions 
and point clouds of the whole scene. %expand/modify?

\paragraph{(a) Hardware setup used during dataset recording:}
%description of various hardware used
\paragraph{(b) Software setup used during dataset recording:}
%1mention we used ROS to sync various hardware
%2talk about calibration steps
%3link and mention github repository where the software is stored
\paragraph{(c) Data collection and description:}
%explain exactly what is recorded and bagfiles
%data format: msgs, tfs, pointclouds
\paragraph{(d) Data usage:}
%talk about how to playback (link)
%talk about what we could extract from recordings and possible uses (grasp planning)
\paragraph{(e) Data access methods:}
%where the data is stored and how a user can access it




