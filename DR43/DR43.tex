\documentclass[a4paper,11pt,pdf]{pacmanreport}

%%=== Aditional packages
\usepackage{amsmath}
\usepackage{amsfonts}

% The following is used to make packages hyperref and cite work together
\makeatletter
\let\NAT@parse\undefined
\makeatother
\usepackage[bookmarks=true,hyperfootnotes=true,colorlinks=true,linkcolor=blue,anchorcolor=blue,citecolor=blue,urlcolor=blue,filecolor=blue]{hyperref}

%%=== Local definitions
\graphicspath{{images/}{../shared_images/}}

%% ================================
%% PROJECT INFO

\project{}
\projectid{FP7-IST-60918}
\projectstart{1 March 2013}
\duration{36}

%% ================================
%% DELIVERABLE INFO

\title{Methodologies for grasp acquisition and planning}
\deliverableid{DR 4.3}
\author{H. Marino, C.J.~Rosales, M. Kopicki, G. Santaera, E. Luberto, Y. Wu, A. Artoni, G. Pannocchia, M. Gabiccini, and J.L.~Wyatt}
\address{University of Birmingham, UK}
\email{jlw@cs.bham.ac.uk}
\headertitle{Grasp acquisition and planning}
\headerauthor{H. Marino, et al.}

\duedate{2016-02-29}
\submissiondate{2016-02-29}
\leadpartner{University of Birmingham, UK}
\revision{final}
\disseminationlevel{PU}


%% UNCOMMENT: to get the logo; if you've copied this file to a directory yearX/wpY/ then this should work
\reportlogo{pacmanlogo.png}


\begin{document}

\maketitle

\begin{abstract}
\noindent This report describes the activities related to \emph{planning and  control of grasping actions} given the complete or partial detection of an object. It includes work on: modelling underactuated and adaptive robotic hands, learning grasps for underactuated hands and transferring them robustly to different initial hand-object poses, adjusting hand pose via infrared sensor readings to grasp objects in an uncertain configuration with the respect to that perceived by vision, planning complex grasping and manipulation tasks either under uncertainty using discrete search methods or via direct trajectory optimization methods for systems with unspecified contact sequences.
\end{abstract}


\vspace{.2em}
\hrule

\footnotesize

\tableofcontents

\normalsize

\newpage

\section*{Executive Summary}

This report describes the activities within the PaCMan consortium to define methodologies for \emph{grasp acquisition and planning}. The material included in this report describes the results that fall under Task 4.3 (M 7-30), and Task 4.4 (M 1-36) at M 36.

\section*{Role of grasp acquisition and planning in PaCMan}

This deliverable documents the effort of the consortium in devising new strategies to define \emph{practical} approaches to tackle the problem of \emph{grasping under uncertainty and novelty}, either caused by sensor noise, clutter, visual occlusions, or new object shapes. To this end, the ability to move through the different stages of the grasping process, from novel shape to grasp formulation, planning reach to grasp, making first contact, updating the belief state, and planning robust or information gathering trajectories are all phases we have tackled during the project.

\section*{Contribution to the PaCMan scenario}

In our view, grasp methodologies that try to cope with pose uncertainty, object shape estimation inaccuracies, object novelty, clutter and partial occlusions are central to PacMan's overall goals. We tackle these by a variety of methods. The grasping methodologies here have all been evaluated on datasets drawn from the PaCMan scenario.

\newpage

\section{Tasks, objectives, results}

\subsection{Planned work}

The selection of correct grasp strategies when the object to be grasped in unknown or only partially visible environments is a trivial task for humans. Although robotics has made significant progress in autonomous grasping, the problem of grasping novel objects in under uncertainty and partial information is still an open area. In this report, we document our work to tackle these problems.

The planned work for the final year involved Tasks 4.3 and Tasks 4.4. These aimed to demonstrate grasp acquisition using our methods for learning and planning under uncertainty, in particular the goal was to demonstrate these on real robot hands, and in particular to the show ability to plan grasps under pose and shape uncertainty and incompleteness. We also promised methods to achieve optimal choice of contact forces during grasp acquisition.  We describe all of these here.

%% Input from Claudio
% In Task 4.4 we posed the problem of grasping as a problem of motion planning under uncertainty. We planned to implement and evaluate a motion planning algorithm in a physics based simulation, prior to transfer to a real robot. The requirement was for an algorithm that could provide robust reach to grasp trajectories in the face of object pose and shape uncertainty, planning for and taking advantage of tactile contacts. We considered both methods that plan explicitly in belief space, and those that embed information from observations in the physical space. We elected to pursue the latter route.


\subsection{Actual work performed}

The work we have performed can be divided into work on learning, planning, and optimisation. We quickly summarise our achievements in each area, before describing the specific contributions in detail. Each of these appraoches directly address our Task 4.3 and 4.4 goals of grasp acquisition and grasp planning and learning under uncertainty and incompleteness.\\

\noindent {\bf Learning:} in previous years we presented our method for learning grasps from small numbers of examples, using a probabilistic approach, which employs a product of experts to provide generalisation of final grasp configurations. This year we have extended this in two ways. First, we present the adaptation to underactuated robotic hands of the grasp planning algorithm previously devised only for fully actuated hands --- the DLR-HIT Hand II was used last year by the University of Birmingham. Our approach, by using a product of experts, learns now not only the desired final grasp, but also good grasping trajectories from rigid body simulations of the Pisa/IIT SoftHand. The new method shows that it is possible to use just a few example grasps in order to be able to transfer this knowledge to unknown, even partially visible objects. This has resulted in a paper to be submitted to IROS. More details can be found in~\ref{ann:LearningInferenceUnderactuatedHands}.  In a second contribution, reported in DR2.2, we have extended our learning method to work with the compositional hierarchy.  In a third piece of work we have extended our approach based on multiple eigenspaces to learning a data-driven taxonomy of grasps. This has been trained on 4500 postures. We describe this in Sec.~\ref{sec:DataDrivenMovementAnalysis}. \\

\noindent {\bf Planning:} with regard to planning under uncertainty and incomplete information we have two strands of work. One is grasping under uncertainty, taking into account the value of tactile information. At a choice point at the end of year 1 we chose to pursue this using a planning method that performed belief space planning by embedding information gains in the physical space. This year we have completed an implementation on the Boris platform, and present the results of this and simulation studies in a draft paper to be submitted to autonomous robots. The work is described in more detail in Sec.~\ref{sec:PlanningUncertainty}. In a second strand we completed our work on high level planning to move objects between locations. Sec.~\ref{sec:HighLevelPlanning} presents our approach to solve this problem, possibly by using handoffs, table support, and regrasping. This work constituted the theoretical foundation for the high-level planning needed to perform Task 5.3 at M24. The planner has now been tested (in simulation) also in more complex scenarios, with respect to bimanual object passing, with promising results.
The good level of maturity reached by the work is testified by the journal publication in~\ref{ann:highLevelPlanning}.  We have also developed sensing and planning to guide grasp acquisition prior to the moment of contact. In Sec.~\ref{sec:IRSensorBasedGraspPlanning}, we describe this work, in which we plan and control the approach trajectory using IR sensors. \\

\noindent {\bf Optimisation:} We have developed our framework for optimisation of contacts and contact forces. Originally we promised to do this only for grasp acquisition. In fact we have gone far beyond this, developing a framework which tackles general manipulation problems. In Sec.~\ref{sec:ComputationalFramework}, we describe a planning strategy based on direct trajectory optimization that does not require a-priori specification of the contact sequence and presents, from the outset, the benefits of providing dynamically consistent plans and allowing for opportunistic exploitation of environmental constraints. This work has now reached a good level of maturity, as testified by the conference publication in~\ref{ann:env-awareManipulation}. In Sec.~\ref{sec:OffsetFreeMPCExplained}, we focus on the description of model predictive control algorithms for nonlinear (and linear) discrete-time systems, with the intended objective of clarifying the main concepts needed to guarantee offset-free performances. A strong accent is put on the role played by the disturbance and the observer models, which are paramount to ensure the stability of MPC-based manipulation controllers derived from manipulation planners described in Sec.~\ref{sec:ComputationalFramework}. More details can be found in the conference publication in~\ref{ann:OffsetFreeMPCExplained}.

We now detail the work for each of these areas in turn.

% \subsection{Relation to the state-of-the-art}
% How are the obtained results related to the state-of-the-art?
% This part is usually discussed in the corresponding subsection. Therefore, % a global 'Relation to the state-of-the-art' is unnecessary

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Work directly into the following .tex files

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Learning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: UoB team and by Hamal MARINO
% Learning and Inference of Dexterous Grasps for Novel Objects with
% Underactuated Hands
\input{./inputFiles/LearningInferenceUnderactuatedHands.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Hamal MARINO
% Data-Driven Human Grasp Movement Analysis
\input{./inputFiles/DataDrivenMovementAnalysis.tex}

\subsection{Planning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Marco GABICCINI
% High-Level Planning for Dual Arm Goal-Oriented Tasks
\input{./inputFiles/PlanningUncertainty.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Marco GABICCINI
% High-Level Planning for Dual Arm Goal-Oriented Tasks
\input{./inputFiles/HighLevelPlanningDualArm.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Yier WU, Emanuele LUBERTO, and Gaspare SANTAERA
% Infrared sensor-based grasp planning
\input{./inputFiles/IRSensorBasedGraspPlanning.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Optimisation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Marco GABICCINI
% Computational Framework for Environment-Aware Robotic Manipulation
% Planning
\input{./inputFiles/ComputationalFramework.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% To be prepared by: Marco GABICCINI
% Offset-free MPC Explained: novelties, subtleties, and applications
%
\input{./inputFiles/OffsetFreeMPCExplained.tex}

\newpage

\bibliographystyle{IEEEtran}
\bibliography{../shared_bibliography/abbreviations,./bibliography/DR43}

\newpage

\appendix
\section{Annexes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Article: On the Problem of Moving Objects with Autonomous Robots: a Unifying High-Level Planning Approach}
\label{ann:highLevelPlanning}
\begin{description}
    \item[Authors] H. Marino, M. Ferrati, A. Settimi, C. Rosales, M. Gabiccini
    \item[Info] Published in: Robotics and Automation Letters, IEEE. Date of Publication: January 18 2016. ISSN: 2377-3766;\\
         DOI: 10.1109/LRA.2016.2519149
    \item[Abstract] Moving objects with autonomous robots is a wide topic that includes single-arm pick-and-place tasks, object regrasping, object passing between two or more arms in the air or using support surfaces such as tables and similar. Each task has been extensively studied and many planning solutions are already present in the literature. In this paper we present a planning scheme which, based on the use of pre-defined elementary manipulation skills, aims to unify solutions which are usually obtained by means of different planning strategies rooted on hard-coded behaviors. Both robotic manipulators and environment fixed support surfaces are treated as end-effectors of movable and non-movable types, respectively. The task of the robot can thus be broken down into elementary building blocks, which are end-effector manipulation skills, that are then planned at the kinematic level. Feasibility is ensured by propagating unforeseen low-level failures at the higher level and by synthesizing different behaviors. The validity of the proposed solution is shown via experiments on a bimanual robot setup and in simulations involving a more complex setup similar to an assembly line.
    \item[Relation with the deliverable] this work is concerned with the problem of planning a grasp sequence to move one object from an initial configuration to a final one. Since the initial configuration is not known a priori, but has to be estimated using vision, nor the sequence of handoffs is pre-specified (but automatically synthesized), the present work contributes to the goals of Task 4.4.
    \item[Attachment] (following pages until next annex)
\end{description}
\includepdf[pages=-]{./attachedPapers/OnTheProblemOfMovingObjectsWithAutonomousRobots.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Article: Enhancing Adaptive Grasp Planning Through a Simple Sensor-based Reflex Mechanism}
\label{ann:IRSensorBasedGraspPlanning}
\begin{description}
    \item[Authors] E. Luberto, G. Santaera, Y. Wu, M. Gabiccini, and A. Bicchi
    \item[Info] Submitted to: 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems
    \item[Abstract] This paper presents an approach to achieve
adaptive grasp of unknown objects whose position is only
approximately known via point-cloud data. We assume no
representation of objects, and no off-line grasp planning.
Rather, we exploit the adaptability of a soft robotic hand
which can autonomously conform to the shape of a grasped
object if properly approached. Once a grasp approach has
been preliminary planned based only on rough estimates of the
object position, the hand is shaped to a pre-grasp configuration.
Before closing the hand, a sensor-based algorithm is applied
that corrects the relative hand-object posture so as to enhance
the probability that the object is “caged” by the fingers. The
algorithm minimizes the distance between the hand’s fingerpads
and the object by continuously controlling the wrist pose and
orientation and the hand closure. Experimental studies with a
Kuka-LWR arm and a Pisa/IIT Softhand illustrate the benefit
of the developed technique and the improvement in grasping
performance with respect to open-loop execution of grasps
planned on the basis of prior RGB-D cues only.
    \item[Relation with the deliverable] this work is concerned with the problem of dealing with uncertainty when performing a grasp with a compliant hand. The present work contributes to the goals of Tasks 4.3 and 4.4.
    \item[Attachment] (following pages until next annex)
\end{description}
\includepdf[pages=-]{./attachedPapers/IRSensorBasedGraspPlanning.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Article: Learning and Inference of Dexterous Grasps for Novel Objects with Underactuated Hands}
\label{ann:LearningInferenceUnderactuatedHands}
\begin{description}
    \item[Authors] M. Kopicki, C. J. Rosales, H. Marino, M. Gabiccini, J. L. Wyatt
    \item[Info] Submitted to: {\color{red} update this and the attached PDF!}
    \item[Abstract] Recent advances have been made in learning of grasps for fully actuated hands. A typical approach learns the target locations of finger links on the object. When a new object must be grasped, new finger locations are generated, and a collision free reach-to-grasp trajectory is planned. Such a division of labour fails to transfer directly to underactuated hands, which improve grasp reliability via contacts with the object during grasping. In this paper we present a method for learning transferrable grasps for underactuated hands. Our approach learns not only the desired final grasp, and also good grasping trajectories, from a rigid body simulation. This enables us to learn how to approach the object and close the underactuated hand from a variety of poses. Our method does not rely on explicit representation of the contact sequence.
The core learning method uses product of experts. This allows grasp transfer to novel objects and works despite partial shape reconstruction of less than 25\% of the surface. From nine training grasps on three objects the method transferred grasps to previously unseen, novel objects, that differ significantly from the training objects, with an 80\% success rate. We move beyond previous work by: i) showing the ability to learn transferrable grasps for underactuated hands; ii) extending our learning
method to work with multiple training examples for each grasp
type; iii) extending our method to work with multiple reach to
grasp trajectories.
    \item[Relation with the deliverable] this work is concerned with the problem of transferring a grasp robustly to different initial hand-object poses for underactuated hands. The present work contributes to the goals of Task 4.4.
    \item[Attachment] (following pages until next annex)
\end{description}
\includepdf[pages=-]{./attachedPapers/LearningInferenceUnderactuatedHands.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Article: Data-Driven Human Grasp Movement Analysis}
\label{ann:DataDrivenHumanGraspMovementAnalysis}
\begin{description}
    \item[Authors] H. Marino, M. Gabiccini, A. Leonardis, and A. Bicchi
    \item[Info] Accepted for presentation in: 47th International Symposium on Robotics (ISR), Munich, Germany, June 21-22, 2016; this version is not final and subject to change up to the submission deadline of March 31, 2016.
    \item[Abstract] The description of human hand motions is very complex, and methods to reduce this complexity have attracted much attention in the motor control literature. Important implications in robot hand design and programming have also generated a wide interest in the robotics research community.
    Early studies prevalently used direct analysis methods such as visual inspection to define grasp taxonomies. More recently, analytical methods have been employed to perform grasping data dimensionality reduction. In this paper, we present a methodology to reconcile these two distinct and apparently incompatible approaches under a unified framework: this allows us to obtain a data-generated grasp taxonomy along with low-dimensional representations which could be used for human grasping data classification and posture reconstruction, as well as for simplifying grasp planning algorithms and robotic hands programming.
%    Humans tend to simplify the space of possible grasps they can perform. This led to the introduction of grasp taxonomies via direct inspection of human movements, and data dimensionality reduction methods for grasp classification, robotic grasp synthesis, and simple hands design. In this paper, we present a methodology to reconcile these two distinct and apparently incompatible approaches under a unified framework, obtaining a data-driven taxonomy that can serve as a link among the aforementioned solutions.
    \item[Relation with the deliverable] this work is concerned with the problem of finding a principled way of analyzing human grasping motion in order to obtain guidelines for the design of hand underactuation mechanisms based on specific tasks to be accomplished.
    \item[Attachment] (following pages until next annex)
\end{description}
\includepdf[pages=-]{./attachedPapers/marino2016datadriven.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Article: A computational framework for environment-aware robotic manipulation planning} \label{ann:env-awareManipulation}
\begin{description}
    \item[Authors] M. Gabiccini, A. Artoni, G. Pannocchia, J.~Gillis
    \item[Info] Published in: 17th International Symposium on Robotics Research (ISRR), Sestri Levante (Genova), Italy, September 12-15, 2015
    \item[Abstract] In this paper, we present a computational framework for direct trajectory optimization of general manipulation systems with unspecified contact sequences, exploiting \emph{environmental constraints} as a key tool to accomplish a task.
    Two approaches are presented to describe the dynamics of systems with contacts, which are based on a penalty formulation and on a velocity-based time-stepping scheme, respectively. In  both cases, object and environment contact forces are included among the free optimization variables, and they are rendered consistent via suitably devised sets of complementarity conditions.
    To maximize computational efficiency, we exploit sparsity patterns in the linear algebra expressions generated during the solution of the optimization problem and leverage Algorithmic Differentiation to calculate derivatives. % quickly and accurately.
    The benefits of the proposed methods are evaluated in three simulated planar manipulation tasks, where essential interactions with environmental constraints are automatically synthesized and opportunistically exploited.
    \item[Relation with the deliverable] grasp and manipulation planning for systems with a-priori unspecified contact sequences.
    \item[Attachment] (following pages until next annex)
\end{description}
\includepdf[pages=-]{./attachedPapers/ComputationalFrameworkEnvAwareRobManipPlanning.pdf}
%\includepdf[pages=-]{./attachedPapers/appendix_of_ComputationalFrameworkEnvAwareRobManipPlanning.pdf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Article: Offset-free MPC explained: novelties, subtleties, and applications}
\label{ann:OffsetFreeMPCExplained}
\begin{description}
    \item[Authors] G. Pannocchia, M. Gabiccini, and A. Artoni
    \item[Info] Published in: 5th IFAC Conference on Nonlinear Model Predictive Control, Seville, Spain, September 17-20, 2015
    \item[Abstract]  This paper presents an updated and comprehensive description of offset-free MPC algorithms for nonlinear (and linear) discrete-time systems, with the intended objectives of clarifying the main concepts, showing new results, highlighting subtleties by means of challenging applications. First, the offset-free tracking problem for nonlinear systems is presented, putting a strong accent on the role of the disturbance model and observer, and then novel and stronger offset-free estimation results are presented. Next, recent advances in linear offset-free MPC are described, which show the equivalence of the velocity form algorithm (so far considered an alternative method) to a particular disturbance model and observer. Then, the concepts of offset-free estimation are exploited to design an offset-free economic MPC algorithm, which can asymptotically achieve the highest economic performance despite persistent model errors and disturbances. Extensive application results are presented to show the benefits of offset-free MPC algorithms over standard ones, and to clarify misconceptions and design errors that can prevent constraint satisfaction, closed-loop stability, and offset-free performance.
    \item[Relation with the deliverable] this work is concerned with providing the necessary theoretical background to design offset-free MPC algorithms, which are fundamental to turn direct trajectory optimization-based manipulation planners (presented in Sec.~\ref{sec:ComputationalFramework}) into controllers able to asymptotically achieve economic performances despite model errors and disturbances.
    \item[Attachment] (following pages until next annex)
\end{description}
\includepdf[pages=-]{./attachedPapers/OffsetFreeMPCExplained.pdf}

\subsection{Article: Active Touch for Grasping}
\label{ann:activetouch}
\begin{description}
    \item[Authors] Claudio Zito, Valerio Ortenzi, Maxime Adjigble, Marek Kopicki and Jeremy L. Wyatt
    \item[Info] To be submitted to: Autonomous Robots
    \item[Abstract]
    \item[Relation with the deliverable]: this paper is central to our work on grasp acquisition under uncertainty. The method we have developed reasons about the uncertainty in the pose of the object, and plans to gather information while reaching the desired grasp state. This places grasp acquisition and active tactile information gathering in a tractable framework.
    \item[Attachment] (following pages until next annex)
\end{description}
%\includepdf[pages=-]{./attachedPapers/OffsetFreeMPCExplained.pdf}

\end{document}
